{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rich_click as click\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def str_ingress(paths, f_format, sample_col, marker_col, sample_map=None):\n",
    "    \"\"\"\n",
    "    Reads in a list of paths and returns a pandas DataFrame of STR alleles in long format.\n",
    "    \"\"\"\n",
    "\n",
    "    samps_dicts = []\n",
    "\n",
    "    for path in paths:\n",
    "        if path.suffix == '.xlsx':\n",
    "            df = pd.read_excel(path)\n",
    "        elif path.suffix == '.csv':\n",
    "            df = pd.read_csv(path)\n",
    "        elif path.suffix == '.tsv':\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "        elif path.suffix == '.txt':\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "        \n",
    "        df = df.applymap(lambda x: x.strip() if type(x)==str else x)\n",
    "\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Collapse allele columns for each marker into a single column if in wide format.\n",
    "        df['Alleles'] = df.filter(like='Allele').apply(lambda x: \n",
    "            ','.join([str(y) for y in x if str(y) != \"nan\"]), axis=1).str.strip(\",\")\n",
    "\n",
    "        # Group and collect dict from each sample for markers and alleles.\n",
    "        grouped = df.groupby(sample_col)\n",
    "\n",
    "        for samp in grouped.groups.keys():\n",
    "            samp_df = grouped.get_group(samp)\n",
    "            samps_dict = samp_df.set_index(marker_col).to_dict()[\"Alleles\"]\n",
    "            samps_dict[\"Sample\"] = samp\n",
    "            \n",
    "            samps_dicts.append(samps_dict)\n",
    "\n",
    "    allele_df = pd.DataFrame(samps_dicts)\n",
    "    \n",
    "    # Replace sample names with sample map if provided.\n",
    "    if sample_map is not None:\n",
    "        for id in sample_map.iloc[:, 0]:\n",
    "            allele_df.loc[allele_df[\"Sample\"] == id, \"Sample\"] = sample_map.iloc[:,1][sample_map.iloc[:,0] == id].to_string(header=False, index=False)\n",
    "    \n",
    "    # Set index to sample name.\n",
    "    allele_df.set_index(\"Sample\", inplace=True, verify_integrity=True)\n",
    "    \n",
    "    # Remove Nans.\n",
    "    allele_df = allele_df.replace({np.nan: ''})\n",
    "    \n",
    "    return allele_df\n",
    "\n",
    "\n",
    "def score_query(query, reference, use_amel=False, amel_col = \"AMEL\"):\n",
    "    \"\"\"\n",
    "    Calculates the Tanabe and Masters scores for a query sample against a reference sample.\n",
    "    \n",
    "    Args:\n",
    "        query (_type_): _description_\n",
    "        reference (_type_): _description_\n",
    "    \"\"\" \n",
    "    \n",
    "    n_r_alleles = 0\n",
    "    n_q_alleles = 0\n",
    "\n",
    "    n_shared_alleles = 0\n",
    "    \n",
    "    # Convert allele values to lists, removing markers with no alleles, and uniquifying alleles.\n",
    "    query = {k: list(set(v.split(\",\"))) for k, v in query.items() if v != \"\"}\n",
    "    reference = {k: list(set(v.split(\",\"))) for k, v in reference.items() if v != \"\"}\n",
    "    \n",
    "    # Get unique markers in query and reference.\n",
    "    markers = list(set(query.keys()) & set(reference.keys()))\n",
    "\n",
    "    # Remove amelogenin markers if use_amel is False.\n",
    "    if use_amel == False:\n",
    "        markers.remove(amel_col)\n",
    "    \n",
    "    # Calculate the number of shared markers.\n",
    "    n_shared_markers = len(markers)\n",
    "    \n",
    "    # Calculate the number of shared alleles.\n",
    "    for m in markers:\n",
    "        n_r_alleles += len(reference[m])\n",
    "        n_q_alleles += len(query[m])\n",
    "        n_shared_alleles += len(set(reference[m]) & set(query[m]))\n",
    "\n",
    "    # Calculate the scores.\n",
    "    tanabe_score = 100 * ((2 * n_shared_alleles) / (n_q_alleles + n_r_alleles))\n",
    "    masters_q_score = 100 * (n_shared_alleles / n_q_alleles)\n",
    "    masters_r_score = 100 * (n_shared_alleles / n_r_alleles)\n",
    "\n",
    "    out = {\"n_markers\": n_shared_markers, \"n_shared_alleles\": n_shared_alleles, \n",
    "           \"n_query_alleles\": n_q_alleles, \"n_reference_alleles\": n_r_alleles, \n",
    "           \"tanabe_score\": tanabe_score, \"masters_q_score\": masters_q_score,\n",
    "           \"masters_r_score\": masters_r_score}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = [Path(\"ExampleSTR.xlsx\"), Path(\"ExampleSTR2.xlsx\")]\n",
    "smap = pd.read_csv(\"SampleMap_exp.csv\", header=None)\n",
    "\n",
    "df = str_ingress(paths = strs, f_format = \"wide\", sample_col = \"Sample Name\", marker_col = \"Marker\", sample_map = smap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps = df.to_dict(orient = \"index\")\n",
    "\n",
    "q = \"Sample1\"\n",
    "\n",
    "for s in samps.keys():\n",
    "    q = samps[q]\n",
    "    \n",
    "    for sa in samps.keys():\n",
    "        if sa != s:\n",
    "            r = samps[sa]\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8a6a806453738a6349acd35cf8220a2a2d41a9d3d229c0f15ac4e1e4327428a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
