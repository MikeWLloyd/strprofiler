{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rich_click as click\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from math import nan\n",
    "\n",
    "def str_ingress(paths, f_format, sample_col, marker_col, sample_map=None, penta_fix=False):\n",
    "    \"\"\"\n",
    "    Reads in a list of paths and returns a pandas DataFrame of STR alleles in long format.\n",
    "    \"\"\"\n",
    "\n",
    "    samps_dicts = []\n",
    "\n",
    "    for path in paths:\n",
    "        path = Path(path)\n",
    "        if path.suffix == '.xlsx':\n",
    "            df = pd.read_excel(path)\n",
    "        elif path.suffix == '.csv':\n",
    "            df = pd.read_csv(path)\n",
    "        elif path.suffix == '.tsv':\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "        elif path.suffix == '.txt':\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "        \n",
    "        df = df.applymap(lambda x: x.strip() if type(x)==str else x)\n",
    "\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Collapse allele columns for each marker into a single column if in wide format.\n",
    "        df['Alleles'] = df.filter(like='Allele').apply(lambda x: \n",
    "            ','.join([str(y).strip() for y in x if str(y) != \"nan\"]), axis=1).str.strip(\",\")\n",
    "\n",
    "        # Group and collect dict from each sample for markers and alleles.\n",
    "        grouped = df.groupby(sample_col)\n",
    "\n",
    "        for samp in grouped.groups.keys():\n",
    "            samp_df = grouped.get_group(samp)\n",
    "            samps_dict = samp_df.set_index(marker_col).to_dict()[\"Alleles\"]\n",
    "            samps_dict[\"Sample\"] = samp\n",
    "            \n",
    "            # Rename PentaD and PentaE from common spellings.\n",
    "            if penta_fix:\n",
    "                if \"Penta D\" in samps_dict.keys():\n",
    "                    samps_dict[\"PentaD\"] = samps_dict.pop(\"Penta D\")\n",
    "                elif \"Penta_D\" in samps_dict.keys():\n",
    "                    samps_dict[\"PentaD\"] = samps_dict.pop(\"Penta_D\")\n",
    "                    \n",
    "                if \"Penta E\" in samps_dict.keys():\n",
    "                    samps_dict[\"PentaE\"] = samps_dict.pop(\"Penta E\")\n",
    "                elif \"Penta_E\" in samps_dict.keys():\n",
    "                    samps_dict[\"PentaE\"] = samps_dict.pop(\"Penta_E\")\n",
    "            \n",
    "            samps_dicts.append(samps_dict)\n",
    "\n",
    "    allele_df = pd.DataFrame(samps_dicts)\n",
    "    \n",
    "    # Replace sample names with sample map if provided.\n",
    "    if sample_map is not None:\n",
    "        for id in sample_map.iloc[:, 0]:\n",
    "            allele_df.loc[allele_df[\"Sample\"] == id, \"Sample\"] = sample_map.iloc[:,1][sample_map.iloc[:,0] == id].to_string(header=False, index=False)\n",
    "    \n",
    "    # Set index to sample name.\n",
    "    allele_df.set_index(\"Sample\", inplace=True, verify_integrity=True)\n",
    "    \n",
    "    # Remove Nans.\n",
    "    allele_df = allele_df.replace({np.nan: ''})\n",
    "    \n",
    "    return allele_df\n",
    "\n",
    "\n",
    "def score_query(query, reference, use_amel=False, amel_col = \"AMEL\"):\n",
    "    \"\"\"\n",
    "    Calculates the Tanabe and Masters scores for a query sample against a reference sample.\n",
    "    \n",
    "    Args:\n",
    "        query (_type_): _description_\n",
    "        reference (_type_): _description_\n",
    "    \"\"\" \n",
    "    \n",
    "    n_r_alleles = 0\n",
    "    n_q_alleles = 0\n",
    "\n",
    "    n_shared_alleles = 0\n",
    "    \n",
    "    # Convert allele values to lists, removing markers with no alleles, and uniquifying alleles.\n",
    "    query = {k: list(set(v.split(\",\"))) for k, v in query.items() if v != \"\"}\n",
    "    reference = {k: list(set(v.split(\",\"))) for k, v in reference.items() if v != \"\"}\n",
    "    \n",
    "    # Get unique markers in query and reference.\n",
    "    markers = list(set(query.keys()) & set(reference.keys()))\n",
    "\n",
    "    # Remove amelogenin markers if use_amel is False.\n",
    "    if use_amel == False:\n",
    "        if amel_col in markers:\n",
    "            markers.remove(amel_col)\n",
    "    \n",
    "    # Calculate the number of shared markers.\n",
    "    n_shared_markers = len(markers)\n",
    "    \n",
    "    # Calculate the number of shared alleles.\n",
    "    for m in markers:\n",
    "        n_r_alleles += len(reference[m])\n",
    "        n_q_alleles += len(query[m])\n",
    "        n_shared_alleles += len(set(reference[m]) & set(query[m]))\n",
    "\n",
    "    # Calculate the scores.\n",
    "    tanabe_score = 100 * ((2 * n_shared_alleles) / (n_q_alleles + n_r_alleles))\n",
    "    masters_q_score = 100 * (n_shared_alleles / n_q_alleles)\n",
    "    masters_r_score = 100 * (n_shared_alleles / n_r_alleles)\n",
    "\n",
    "    out = {\"n_shared_markers\": n_shared_markers, \"query_sample\": False,\n",
    "           \"n_shared_alleles\": n_shared_alleles, \n",
    "           \"n_query_alleles\": n_q_alleles, \"n_reference_alleles\": n_r_alleles, \n",
    "           \"tanabe_score\": tanabe_score, \"masters_query_score\": masters_q_score,\n",
    "           \"masters_ref_score\": masters_r_score}\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def mixing_check(alleles, three_allele_threshold = 3):\n",
    "    \"\"\"Checks for potential sample mixing.\n",
    "\n",
    "    Args:\n",
    "        alleles (_type_): _description_\n",
    "        three_allele_threshold (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    mixed = False\n",
    "    past_th = 0\n",
    "    \n",
    "    for a in alleles:\n",
    "        all_a = alleles[a].split(\",\")\n",
    "        if len(all_a) > 2:\n",
    "            past_th += 1\n",
    "    \n",
    "    if past_th > three_allele_threshold:\n",
    "        mixed = True\n",
    "    \n",
    "    return mixed\n",
    "\n",
    "\n",
    "def make_summary(samp_df, alleles, tan_threshold, mas_q_threshold, mas_r_threshold, mixed, s_name):\n",
    "    \"\"\"Generate summary line from full sample-specific output.\n",
    "\n",
    "    Args:\n",
    "        samp_df (_type_): _description_\n",
    "        tan_threshold (_type_): _description_\n",
    "        mas_q_threshold (_type_): _description_\n",
    "        mas_r_threshold (_type_): _description_\n",
    "        mixed (_type_): _description_\n",
    "        s_name (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    tanabe_match = samp_df[samp_df[\"tanabe_score\"] >= tan_threshold]\n",
    "    tanabe_out = tanabe_match[\"Sample\"] + \": \" + tanabe_match[\"tanabe_score\"].round(decimals=2).astype(str)\n",
    "    tanabe_out = tanabe_out.tolist()\n",
    "    tanabe_out = \"; \".join(tanabe_out)\n",
    "    \n",
    "    masters_q_match = samp_df[samp_df[\"masters_query_score\"] >= mas_q_threshold]\n",
    "    masters_q_out = masters_q_match[\"Sample\"] + \": \" + masters_q_match[\"masters_query_score\"].round(decimals=2).astype(str)\n",
    "    masters_q_out = masters_q_out.tolist()\n",
    "    masters_q_out = \"; \".join(masters_q_out)\n",
    "    \n",
    "    masters_r_match = samp_df[samp_df[\"masters_ref_score\"] >= mas_r_threshold]\n",
    "    masters_r_out = masters_r_match[\"Sample\"] + \": \" + masters_r_match[\"masters_ref_score\"].round(decimals=2).astype(str)\n",
    "    masters_r_out = masters_r_out.tolist()\n",
    "    masters_r_out = \"; \".join(masters_r_out)\n",
    "    \n",
    "    summ_out = OrderedDict({\"Sample\": s_name, \"mixed\": mixed, \"tanabe_matches\": tanabe_out, \n",
    "                            \"masters_query_matches\": masters_q_out, \"masters_ref_matches\": masters_r_out})\n",
    "    summ_out.update(alleles)\n",
    "    \n",
    "    return summ_out\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"-tanth\", \"--tan_threshold\", default=80, \n",
    "              help=\"Minimum Tanabe score to report as potential matches in summary table.\", \n",
    "              show_default=True, type=float)\n",
    "@click.option(\"-masqth\", \"--mas_q_threshold\", default=80, \n",
    "              help=\"Minimum Masters (vs. query) score to report as potential matches in summary table.\", \n",
    "              show_default=True, type=float)\n",
    "@click.option(\"-masrth\", \"--mas_r_threshold\", default=80, \n",
    "              help=\"Minimum Masters (vs. reference) score to report as potential matches in summary table.\", \n",
    "              show_default=True, type=float)\n",
    "@click.option(\"-mix\", \"--mix_threshold\", default=3, \n",
    "              help=\"Number of markers with >= 2 alleles allowed before a sample is flagged for potential mixing.\", \n",
    "              show_default=True, type=int)\n",
    "@click.option(\"-f\", \"--fmt\", \n",
    "              help=\"\"\"Format of STR profile(s). Can be 'long' or 'wide'. \n",
    "              If 'long', all columns except the sample column are presumed to be markers.\"\"\", \n",
    "              default = \"long\", show_default=True, \n",
    "              type=click.Choice(['long', 'wide'], case_sensitive=False))\n",
    "@click.option(\"-sm\", \"--sample_map\", help=\"Path to sample map for renaming.\", type=click.Path())\n",
    "@click.option(\"-acol\", \"--amel_col\", help=\"Name of Amelogenin column in STR file(s). Excluded form scoring.\", \n",
    "              default = \"AMEL\", show_default=True, type=str)\n",
    "@click.option(\"-scol\", \"--sample_col\", help=\"Name of sample column in STR file(s).\", \n",
    "              default = \"Sample\", show_default=True, type=str)\n",
    "@click.option(\"-mcol\", \"--marker_col\", help=\"\"\"Name of marker column in STR file(s).\n",
    "              Only used if format is 'wide'.\"\"\", \n",
    "              default = \"Marker\", show_default=True, type=str)\n",
    "@click.option(\"-pfix\", \"--penta_fix\", help=\"\"\"Whether to try to harmonize PentaE/D allele spelling.\"\"\", \n",
    "              default = True, show_default=True, type=bool)\n",
    "@click.option(\"-o\", \"--output_dir\", default=\"./STRprofiler\", \n",
    "              help=\"Path to the output directory.\", show_default=True, type=click.Path())\n",
    "@click.argument(\"input_files\", required=True, type=click.Path(exists=True), nargs = -1)\n",
    "@click.version_option()\n",
    "def strprofiler(input_files, sample_map = None, output_dir = \"./STRprofiler\", \n",
    "                tan_threshold = 80, mas_q_threshold = 80, \n",
    "                mas_r_threshold = 80, mix_threshold = 4, fmt = \"long\", \n",
    "                amel_col = \"AMEL\", sample_col = \"Sample Name\", \n",
    "                marker_col = \"Marker\", penta_fix = True):\n",
    "    \"\"\"STRprofiler compares STR profiles to each other.\"\"\"\n",
    "\n",
    "    # Make output directory and open file for logging.\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%Y%m%d.%H_%M_%S\")\n",
    "    log_file = open(\n",
    "        Path(output_dir, \"strprofiler.\" + dt_string + \".log\"), \"w\")\n",
    "\n",
    "    print(\"Tanabe threshold: \" + str(tan_threshold), file=log_file)\n",
    "    print(\"Masters (vs. query) threshold: \" + str(mas_q_threshold), file=log_file)\n",
    "    print(\"Masters (vs. reference) threshold: \" + str(mas_r_threshold), file=log_file)\n",
    "    print(\"Mix threshold: \" + str(mix_threshold), file=log_file)\n",
    "    print(\"Format: \" + fmt, file=log_file)\n",
    "    print(\"Sample map: \" + sample_map, file=log_file)\n",
    "    print(\"Amelogenin column: \" + amel_col, file=log_file)\n",
    "    print(\"Sample column: \" + sample_col, file=log_file)\n",
    "    print(\"Marker column: \" + marker_col, file=log_file)\n",
    "    print(\"Penta fix: \" + str(penta_fix), file=log_file)\n",
    "    \n",
    "    # Check for sample map.\n",
    "    if sample_map is not None:\n",
    "        sample_map = pd.read_csv(sample_map, header=None, encoding= \"unicode_escape\")\n",
    "    \n",
    "    # Data ingress.\n",
    "    df = str_ingress(paths = input_files, f_format = fmt, sample_col = sample_col, \n",
    "                     marker_col = marker_col, sample_map = sample_map, penta_fix = penta_fix)\n",
    "    \n",
    "    samps = df.to_dict(orient = \"index\")\n",
    "    summaries = []\n",
    "\n",
    "    # Iterate through samples and compare to each other.\n",
    "    for s in samps.keys():\n",
    "        q = samps[s]\n",
    "        # Check for sample mixing.\n",
    "        mixed = mixing_check(alleles = q, three_allele_threshold = mix_threshold)\n",
    "        \n",
    "        q_out = {\"Sample\": s, \"mixed\": mixed, \"query_sample\": True, \n",
    "                 \"n_shared_markers\": nan, \"n_shared_alleles\": nan, \n",
    "                 \"n_query_alleles\": nan, \"n_reference_alleles\": nan, \n",
    "                 \"tanabe_score\": nan, \"masters_query_score\": nan,\n",
    "                 \"masters_ref_score\": nan}\n",
    "        q_out.update(q)\n",
    "        \n",
    "        # Put query sample first.\n",
    "        samp_comps = [q_out]\n",
    "        \n",
    "        for sa in samps.keys():\n",
    "            if sa != s:\n",
    "                r = samps[sa]\n",
    "                print(\"Comparing \" + s + \" to \" + sa, file = log_file)\n",
    "                scores = score_query(query = q, reference = r)\n",
    "                \n",
    "                # Create dict of scores for each sample comparison.\n",
    "                samp_out = OrderedDict({\"Sample\": sa})\n",
    "                samp_out.update(scores)\n",
    "                samp_out.update(r)\n",
    "                \n",
    "                samp_comps.append(samp_out)\n",
    "                \n",
    "        # Create DataFrame of scores for each sample comparison.\n",
    "        full_samp_out = pd.DataFrame(samp_comps)\n",
    "        full_samp_out.sort_values(by=\"tanabe_score\", ascending = False, inplace=True, na_position = \"first\")\n",
    "        \n",
    "        # Write sample-specific output.\n",
    "        full_samp_out.to_csv(Path(output_dir, s + \".strprofiler.\" + dt_string + \".csv\"), index = False)\n",
    "        \n",
    "        # Generate summary of scores for given sample.\n",
    "        summ = make_summary(samp_df = full_samp_out, alleles = q, \n",
    "                            tan_threshold = tan_threshold, \n",
    "                            mas_q_threshold = mas_q_threshold, \n",
    "                            mas_r_threshold = mas_r_threshold, mixed = mixed, s_name = s)\n",
    "        \n",
    "        summaries.append(summ)\n",
    "        \n",
    "    summaries = pd.DataFrame(summaries)\n",
    "    # Write summary output.\n",
    "    summaries.to_csv(Path(output_dir, \"full_summary.strprofiler\" + dt_string + \".csv\"), index = False)\n",
    "    \n",
    "    cell_hover = {  # for row hover use <tr> instead of <td>\n",
    "    'selector': 'td:hover',\n",
    "    'props': [('background-color', '#ffffb3')]\n",
    "    }\n",
    "    index_names = {\n",
    "        'selector': '.index_name',\n",
    "        'props': 'font-style: italic; color: darkgrey; font-weight:normal;'\n",
    "    }\n",
    "    headers = {\n",
    "        'selector': 'th:not(.index_name)',\n",
    "        'props': 'background-color: #000066; color: white;'\n",
    "    }\n",
    "    summaries.set_table_styles([cell_hover, index_names, headers])\n",
    "    summaries.to_html(Path(output_dir, \"full_summary.strprofiler\" + dt_string + \".html\"), index = False)\n",
    "    \n",
    "    log_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Context.__init__() got an unexpected keyword argument 'input_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/jandrews/Documents/GitHub/strprofiler/testing.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/jandrews/Documents/GitHub/strprofiler/testing.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m strprofiler(input_files \u001b[39m=\u001b[39;49m [Path(\u001b[39m\"\u001b[39;49m\u001b[39mExampleSTR.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m), Path(\u001b[39m\"\u001b[39;49m\u001b[39mExampleSTR2.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m)], output_dir \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m./STRprofiler\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/jandrews/Documents/GitHub/strprofiler/testing.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m             tan_threshold \u001b[39m=\u001b[39;49m \u001b[39m80\u001b[39;49m, mas_q_threshold \u001b[39m=\u001b[39;49m \u001b[39m80\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/jandrews/Documents/GitHub/strprofiler/testing.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m             mas_r_threshold \u001b[39m=\u001b[39;49m \u001b[39m80\u001b[39;49m, mix_threshold \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m, fmt \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mwide\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/jandrews/Documents/GitHub/strprofiler/testing.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m             amel_col \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mAMEL\u001b[39;49m\u001b[39m\"\u001b[39;49m, sample_col \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mSample Name\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/jandrews/Documents/GitHub/strprofiler/testing.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m             marker_col \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mMarker\u001b[39;49m\u001b[39m\"\u001b[39;49m, sample_map \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mSampleMap_exp.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/click/core.py:1128\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     rv \u001b[39m=\u001b[39m shell_complete(\u001b[39mself\u001b[39m, ctx_args, prog_name, complete_var, instruction)\n\u001b[1;32m   1126\u001b[0m     sys\u001b[39m.\u001b[39mexit(rv)\n\u001b[0;32m-> 1128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m   1129\u001b[0m     \u001b[39m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/rich_click/rich_command.py:19\u001b[0m, in \u001b[0;36mRichCommand.main\u001b[0;34m(self, standalone_mode, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, standalone_mode: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m         rv \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mmain(\u001b[39m*\u001b[39;49margs, standalone_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     20\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m standalone_mode:\n\u001b[1;32m     21\u001b[0m             \u001b[39mreturn\u001b[39;00m rv\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/click/core.py:1052\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39m# Process shell completion requests and exit early.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_main_shell_completion(extra, prog_name, complete_var)\n\u001b[0;32m-> 1052\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1053\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_context(prog_name, args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra) \u001b[39mas\u001b[39;00m ctx:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3/lib/python3.10/site-packages/click/core.py:909\u001b[0m, in \u001b[0;36mmake_context\u001b[0;34m(self, info_name, args, parent, **extra)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_context\u001b[39m(\n\u001b[1;32m    885\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    886\u001b[0m     info_name: t\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra: t\u001b[39m.\u001b[39mAny,\n\u001b[1;32m    890\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Context:\n\u001b[1;32m    891\u001b[0m     \u001b[39m\"\"\"This function when given an info name and arguments will kick\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    off the parsing and create a new :class:`Context`.  It does not\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[39m    invoke the actual command callback though.\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \n\u001b[1;32m    895\u001b[0m \u001b[39m    To quickly customize the context class used without overriding\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[39m    this method, set the :attr:`context_class` attribute.\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \n\u001b[1;32m    898\u001b[0m \u001b[39m    :param info_name: the info name for this invocation.  Generally this\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[39m                      is the most descriptive name for the script or\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39m                      command.  For the toplevel script it's usually\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m                      the name of the script, for commands below it it's\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m                      the name of the command.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m    :param args: the arguments to parse as list of strings.\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[39m    :param parent: the parent context if available.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[39m    :param extra: extra keyword arguments forwarded to the context\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[39m                  constructor.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \n\u001b[1;32m    908\u001b[0m \u001b[39m    .. versionchanged:: 8.0\u001b[39;00m\n\u001b[0;32m--> 909\u001b[0m \u001b[39m        Added the :attr:`context_class` attribute.\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext_settings\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    912\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m extra:\n",
      "\u001b[0;31mTypeError\u001b[0m: Context.__init__() got an unexpected keyword argument 'input_files'"
     ]
    }
   ],
   "source": [
    "strprofiler([Path(\"ExampleSTR.xlsx\"), Path(\"ExampleSTR2.xlsx\")], output_dir = \"./STRprofiler\", \n",
    "            tan_threshold = 80, mas_q_threshold = 80, \n",
    "            mas_r_threshold = 80, mix_threshold = 4, fmt = \"wide\", \n",
    "            amel_col = \"AMEL\", sample_col = \"Sample Name\", \n",
    "            marker_col = \"Marker\", sample_map = \"SampleMap_exp.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import nan\n",
    "\n",
    "\n",
    "samps = df.to_dict(orient = \"index\")\n",
    "\n",
    "summaries = []\n",
    "\n",
    "for s in samps.keys():\n",
    "    q = samps[s]\n",
    "    q_out = {\"Sample\": s, \"query_sample\": True, \"n_shared_markers\": nan, \"n_shared_alleles\": nan, \n",
    "           \"n_query_alleles\": nan, \"n_reference_alleles\": nan, \n",
    "           \"tanabe_score\": nan, \"masters_query_score\": nan,\n",
    "           \"masters_ref_score\": nan}\n",
    "    q_out.update(q)\n",
    "    \n",
    "    # Put query sample first.\n",
    "    samp_comps = [q_out]\n",
    "      \n",
    "    for sa in samps.keys():\n",
    "        if sa != s:\n",
    "            r = samps[sa]\n",
    "            \n",
    "            scores = score_query(query = q, reference = r)\n",
    "            \n",
    "            # Create dict of scores for each sample comparison.\n",
    "            samp_out = OrderedDict({\"Sample\": sa})\n",
    "            samp_out.update(scores)\n",
    "            samp_out.update(r)\n",
    "            \n",
    "            samp_comps.append(samp_out)\n",
    "            \n",
    "    # Create DataFrame of scores for each sample comparison.\n",
    "    full_samp_out = pd.DataFrame(samp_comps)\n",
    "    full_samp_out.sort_values(by=\"tanabe_score\", ascending = False, inplace=True, na_position = \"first\")\n",
    "    \n",
    "    \n",
    "    # Generate summary of scores for given sample.\n",
    "    match = mixing_check(q)\n",
    "    summ = make_summary(full_samp_out, q, 80, 80, 80, match, s)\n",
    "    \n",
    "    summaries.append(summ)\n",
    "    \n",
    "summaries = pd.DataFrame(summaries)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8a6a806453738a6349acd35cf8220a2a2d41a9d3d229c0f15ac4e1e4327428a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
